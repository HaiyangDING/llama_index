{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn Llama_index\n",
    "\n",
    "Doc [Llama_index with Azure OpenAI](https://docs.llamaindex.ai/en/stable/examples/customization/llms/AzureOpenAI/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start from basic examples. Using Azure OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "World\n"
     ]
    }
   ],
   "source": [
    "print ('Hello')\n",
    "\n",
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(\n",
    "    stream=sys.stdout, level=logging.INFO\n",
    ")  # logging.DEBUG for more verbose output\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "print ('World')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "api_key = os.environ[\"api_key\"]\n",
    "azure_endpoint = os.environ[\"azure_endpoint\"]\n",
    "api_version = os.environ[\"api_version\"]\n",
    "\n",
    "llm = AzureOpenAI(\n",
    "    model=\"gpt-35-turbo\",\n",
    "    deployment_name=\"gpt35\",\n",
    "    api_key=api_key,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    api_version=api_version,\n",
    ")\n",
    "\n",
    "# You need to deploy your own embedding model as well as your own chat completion model\n",
    "embed_model = AzureOpenAIEmbedding(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    deployment_name=\"embedding-ada-002\",\n",
    "    api_key=api_key,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    api_version=api_version,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://haiyang-azopenai-test.openai.azure.com//openai/deployments/embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://haiyang-azopenai-test.openai.azure.com//openai/deployments/embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://haiyang-azopenai-test.openai.azure.com//openai/deployments/embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://haiyang-azopenai-test.openai.azure.com//openai/deployments/embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://haiyang-azopenai-test.openai.azure.com//openai/deployments/embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://haiyang-azopenai-test.openai.azure.com//openai/deployments/embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[\"./paul_graham_essay.txt\"]\n",
    ").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://haiyang-azopenai-test.openai.azure.com//openai/deployments/embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://haiyang-azopenai-test.openai.azure.com//openai/deployments/embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://haiyang-azopenai-test.openai.azure.com//openai/deployments/gpt35/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://haiyang-azopenai-test.openai.azure.com//openai/deployments/gpt35/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "> Source (Doc id: 74b0de7e-ccf5-4e8e-beee-4de897408c91): Notes\n",
      "\n",
      "[1] My experience skipped a step in the evolution of computers: time-sharing machines wi...\n",
      "\n",
      "> Source (Doc id: 468b3560-e80e-4102-ae67-632389d42671): What I Worked On\n",
      "\n",
      "February 2021\n",
      "\n",
      "Before college the two main things I worked on, outside of s...\n",
      "query was: What is most interesting about this essay?\n",
      "answer was: The most interesting aspect of this essay is the author's personal journey and experiences with writing and programming, from his early attempts at writing short stories to his exploration of programming on different computer systems. The essay provides insights into the author's development as a writer and programmer, as well as his evolving interests and aspirations.\n"
     ]
    }
   ],
   "source": [
    "query = \"What is most interesting about this essay?\"\n",
    "query_engine = index.as_query_engine()\n",
    "answer = query_engine.query(query)\n",
    "\n",
    "print(answer.get_formatted_sources())\n",
    "print(\"query was:\", query)\n",
    "print(\"answer was:\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn 'Query pipeline'\n",
    "\n",
    "[llama_index/blob/main/docs/docs/examples/pipeline/query_pipeline.ipynb](https://github.com/run-llama/llama_index/blob/main/docs/docs/examples/pipeline/query_pipeline.ipynb)\n",
    "\n",
    "### Setup\n",
    "\n",
    "Error.\n",
    "\n",
    "```shell\n",
    "Traceback (most recent call last):\n",
    "\n",
    "  File c:\\Users\\haiyang\\miniconda3\\envs\\llamaindex\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3553 in run_code\n",
    "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
    "\n",
    "  Cell In[2], line 2\n",
    "    import phoenix as px\n",
    "\n",
    "  File c:\\Users\\haiyang\\miniconda3\\envs\\llamaindex\\Lib\\site-packages\\phoenix\\__init__.py:56\n",
    "    except PhoenixError, e:\n",
    "           ^\n",
    "SyntaxError: multiple exception types must be parenthesized\n",
    "```\n",
    "\n",
    "Try `pip install llama-index-callbacks-arize-phoenix`.\n",
    "\n",
    "Error with install `llama-index-callbacks-arize-phoenix`:\n",
    "\n",
    "```shell\n",
    "      building 'hdbscan._hdbscan_tree' extension\n",
    "      error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
    "      [end of output]\n",
    "\n",
    "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
    "  ERROR: Failed building wheel for hdbscan\n",
    "Failed to build hdbscan\n",
    "ERROR: Could not build wheels for hdbscan, which is required to install pyproject.toml-based projects\n",
    "```\n",
    "\n",
    "Try install MS Visual Studio (with only C++ related options) [ref](https://github.com/run-llama/llama_index/issues/10602#issuecomment-1939692627)\n",
    "\n",
    "This fixes the issue in installing `llama-index-callbacks-arize-phoenix`\n",
    "\n",
    "After `llama-index-callbacks-arize-phoenix` installed, the `import phoenix as px` issue is fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\haiyang\\miniconda3\\envs\\llamaindex\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŒ To view the Phoenix app in your browser, visit http://localhost:6006/\n",
      "ðŸ“º To view the Phoenix app in a notebook, run `px.active_session().view()`\n",
      "ðŸ“– For more information on how to use Phoenix, check out https://docs.arize.com/phoenix\n"
     ]
    }
   ],
   "source": [
    "# setup Arize Phoenix for logging/observability\n",
    "import phoenix as px\n",
    "\n",
    "px.launch_app()\n",
    "import llama_index.core\n",
    "\n",
    "llama_index.core.set_global_handler(\"arize_phoenix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
    "from llama_index.core import Settings\n",
    "\n",
    "# Settings.llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "# Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")\n",
    "\n",
    "llm = AzureOpenAI(\n",
    "    model=\"gpt-35-turbo\",\n",
    "    deployment_name=\"gpt35\",\n",
    "    api_key=api_key,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    api_version=api_version,\n",
    ")\n",
    "\n",
    "# You need to deploy your own embedding model as well as your own chat completion model\n",
    "embed_model = AzureOpenAIEmbedding(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    deployment_name=\"embedding-ada-002\",\n",
    "    api_key=api_key,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    api_version=api_version,\n",
    ")\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://haiyang-azopenai-test.openai.azure.com//openai/deployments/embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://haiyang-azopenai-test.openai.azure.com//openai/deployments/embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://haiyang-azopenai-test.openai.azure.com//openai/deployments/embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://haiyang-azopenai-test.openai.azure.com//openai/deployments/embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://haiyang-azopenai-test.openai.azure.com//openai/deployments/embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://haiyang-azopenai-test.openai.azure.com//openai/deployments/embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "reader = SimpleDirectoryReader(\"./paul_graham\")\n",
    "\n",
    "docs = reader.load_data()\n",
    "\n",
    "import os\n",
    "from llama_index.core import (\n",
    "    StorageContext,\n",
    "    VectorStoreIndex,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "\n",
    "if not os.path.exists(\"storage\"):\n",
    "    index = VectorStoreIndex.from_documents(docs)\n",
    "    # save index to disk\n",
    "    index.set_index_id(\"vector_index\")\n",
    "    index.storage_context.persist(\"./storage\")\n",
    "else:\n",
    "    # rebuild storage context\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=\"storage\")\n",
    "    # load index\n",
    "    index = load_index_from_storage(storage_context, index_id=\"vector_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain together Prompt and LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_pipeline import QueryPipeline\n",
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "# try chaining basic prompts\n",
    "prompt_str = \"Please generate related movies to {movie_name}\"\n",
    "prompt_tmpl = PromptTemplate(prompt_str)\n",
    "llm = AzureOpenAI(\n",
    "    model=\"gpt-35-turbo\",\n",
    "    deployment_name=\"gpt35\",\n",
    "    api_key=api_key,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    api_version=api_version,\n",
    ")\n",
    "\n",
    "p = QueryPipeline(chain=[prompt_tmpl, llm], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;155;135;227m> Running module 02de9f7b-551e-4964-82a9-a2da152a49d2 with input: \n",
      "movie_name: The Departed\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module 9f252eda-f354-4a13-9c95-c6ce4a39421f with input: \n",
      "messages: Please generate related movies to The Departed\n",
      "\n",
      "\u001b[0mINFO:httpx:HTTP Request: POST https://haiyang-azopenai-test.openai.azure.com//openai/deployments/gpt35/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://haiyang-azopenai-test.openai.azure.com//openai/deployments/gpt35/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "output = p.run(movie_name=\"The Departed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: 1. Infernal Affairs (2002) - This Hong Kong crime thriller is the original film that inspired The Departed. It follows a similar storyline of undercover cops infiltrating a criminal organization.\n",
      "\n",
      "2. Internal Affairs (1990) - This American crime thriller starring Richard Gere and Andy Garcia revolves around a corrupt cop and an internal affairs officer determined to expose him.\n",
      "\n",
      "3. The Town (2010) - Directed by and starring Ben Affleck, this crime drama follows a group of bank robbers in Boston who find themselves in a dangerous situation when they take a hostage during a heist.\n",
      "\n",
      "4. Heat (1995) - Directed by Michael Mann, this crime thriller features Al Pacino and Robert De Niro as a detective and a professional thief, respectively, whose paths cross in a high-stakes game of cat and mouse.\n",
      "\n",
      "5. The Departed (2006) - Although it's the same movie as the one mentioned in the prompt, it's worth noting that The Departed itself is a highly acclaimed crime drama directed by Martin Scorsese, starring Leonardo DiCaprio, Matt Damon, and Jack Nicholson. It follows the intertwining lives of an undercover cop and a mole in the police force.\n",
      "\n",
      "6. Donnie Brasco (1997) - Based on a true story, this crime drama stars Johnny Depp as an undercover FBI agent who infiltrates the mob and forms a close bond with a low-level mobster played by Al Pacino.\n",
      "\n",
      "7. American Gangster (2007) - This crime film, directed by Ridley Scott, is based on the true story of Frank Lucas, a drug lord in Harlem during the 1970s, and the detective who is determined to bring him down, played by Russell Crowe.\n",
      "\n",
      "8. Training Day (2001) - Denzel Washington won an Academy Award for his portrayal of a corrupt narcotics detective who takes a rookie cop, played by Ethan Hawke, on a day-long journey through the dangerous streets of Los Angeles.\n",
      "\n",
      "9. The Godfather (1972) - Francis Ford Coppola's iconic crime film follows the Corleone crime family and their rise to power in the world of organized crime. It stars Marlon Brando, Al Pacino, and James Caan.\n",
      "\n",
      "10. The Untouchables (1987) - Directed by Brian De Palma, this crime drama tells the story of Eliot Ness, a federal agent who forms a team to take down the notorious gangster Al Capone during the Prohibition era. It stars Kevin Costner, Sean Connery, and Robert De Niro.\n"
     ]
    }
   ],
   "source": [
    "print(str(output))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
